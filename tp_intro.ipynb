{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP - 1. Introduction à scikit-learn - classification\n",
    "\n",
    "Dans ce notebook, vous allez apprendre :\n",
    "* à vous servir d'un notebook Jupyter pour garder une trace de l'analyse de vos données ;\n",
    "* à vous familiariser avec la librairie scikit-learn;\n",
    "* à developper un premier algorithme de classification.\n",
    "\n",
    "Ce noteboook utilise les librairies suivantes :\n",
    "* python 3.7.7\n",
    "* numpy 1.18.4\n",
    "* matplotlib 3.2.1\n",
    "* scikit-learn 0.23.1\n",
    "\n",
    "Pour vérifier quelles versions de ces librairies vous utilisez, faites tourner la cellue ci-dessous en cliquant dessus puis en cliquant sur le bouton \"Play\" dans le menu au-dessus de cette fenêtre, ou en tapant Shift+Enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "import numpy\n",
    "print(numpy.__version__)\n",
    "\n",
    "import matplotlib\n",
    "print(matplotlib.__version__)\n",
    "\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  Le notebook Jupyter\n",
    "\n",
    "Jupyter est une application web qui vous permet de créer et partager des documents appelés _notebooks_ (tels que ce notebook .ipynb) qui contient du code modifiable et exécutable, des visualisations, et du texte explicatoire qui peut être formaté avec une syntaxe markdown simple et contenir des équations.\n",
    "\n",
    "Quelques éléments concernant l'utilisation des notebooks Jupyter :\n",
    "* Chaque bloc éditable est contenu dans une cellule (_cell_). Un cellule peut contenit du texte brut (_raw text_), du code, ou du texte formatté avec la syntaxe markdown, comme cette cellule. Pour plus d'information sur la syntaxe markdown, suivez le [guide](http://jupyter-notebook.readthedocs.io/en/latest/examples/Notebook/Working%20With%20Markdown%20Cells.html) !\n",
    "* Pour exécuter une cellule, il suffit de cliquer dessus et de taper Shift+Enter (ou d'utiliser le bouton Play dans la barre de menu).\n",
    "* Pour créer une nouvelle cellule vide en-dessous de celle que vous allez exécuter, utilisez Alt+Enter au lieu de Shift+Enter.\n",
    "* Le menu Insert vous permet aussi d'insérer de nouvelles cellules avant ou après la cellue courante.\n",
    "* Si le notebook ne répond plus, vous pouvez le redémarrer par le menu Kernel --> Restart.\n",
    "\n",
    "Quelques éléments concernant l'utilisation d'un notebook Jupyter avec Python :\n",
    "* Une cellule de code Python se comporte comme un shell Python interactif (et en particulier comme ipython, sur lequel est basé Jupyter). En particulier : \n",
    "  * Tabulation permet d'auto-compléter le mot-clé que vous avez commencé à taper\n",
    "  * Taper un point d'interrogation après le nom d'un objet charge l'aide interactive pour cette fonction.\n",
    "* Jupyter a des commandes Python spéciales (des raccourcis, en quelque sorte) qui s'appellent des _magics_. Par exemple, `%bash` permet d'exécuter du code bash (donc comme si vous étiez dans un terminal), `%paste` permet de coller un block de code précédemment copié (depuis le notebook ou une autre application) en conservant son formatage (et en particulier les indentations), et `%matplotlib inline` permet d'importer la librairie de visualisation de matplotlib et d'afficher les graphiques créés non pas dans une nouvelle fenêtre mais à l'intérieur du notebook. Vous trouverez une liste complète de _magics_ sur http://ipython.readthedocs.io/en/stable/interactive/magics.html \n",
    "\n",
    "\n",
    "### Ressources \n",
    "* Pour en savoir plus sur le shell python interactif : http://ipython.readthedocs.io/en/stable/interactive/tutorial.html\n",
    "* Pour en savoir plus sur Jupyter : https://jupyter.org/\n",
    "* Python et Python Scientifique : http://www.scipy-lectures.org/\n",
    "* Pour une introduction rapide aux différences entre shell python, shell python interactif, et notebook : https://www.youtube.com/watch?v=ULzWaZQa1Dc (en français)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe les packages classiques de calcul et de visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gestion des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce TP a pour but de vous familiariser avec scikit-learn, d'apprendre et d'utiliser les modèles proposés par cette librairie.\n",
    "\n",
    "On utilisera une version simplifiée du classique jeu de donnée MNIST, digits, dont les élements sont des images de chiffres tracés à la main.\n",
    "Ici chaque image est de dimension `8x8`.\n",
    "Importons le."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()\n",
    "print(digits.data.shape)\n",
    "print(digits.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'attribut `data` d'un dataset sklearn a systématiquement les dimensions `(n_samples, n_features)`.\n",
    "Ici une ligne correspond donc à une image \"aplatie\". On peut les afficher en restructurant ce vecteur grace à la méthode `.reshape` d'un tableau numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot des 16 premiers éléments du dataset.\n",
    "for i in range(16):\n",
    "    ax = plt.subplot(4, 4, i+1)\n",
    "    ax.imshow(digits.data[i,:].reshape((8,8)), cmap='Greys')\n",
    "    ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data` et `target` sont deux des attributs de ce jeu de données.\n",
    "Il est possible de lister les attributs et méthodes d'une classe avec `dir(object)`.\n",
    "\n",
    "**Question:**\n",
    "\n",
    "> Y avait-il un moyen plus simple d'afficher les images ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Réponse**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but sera ici d'apprendre à classifier ces image, les classes étant les numéros représentés (10 classes donc).\n",
    "\n",
    "Pour évaluer le classifieur, il nous faut un jeu de donné de test indépendant de celui d'entrainement.\n",
    "On peut séparer aléatoirement le jeu de données en un `train` et un `test` grâce à [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data_train, data_test, label_train, label_test = train_test_split(digits.data, digits.target, \n",
    "                                                                    test_size=0.3, random_state=84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(label_test)\n",
    "plt.xlabel('test labels')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(label_train)\n",
    "plt.xlabel('train labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si la séparation est faite totalement aléatoirement et que la base de donnée n'est pas suffisamment grande, on peut avoir une répartition inégale des labels au sein du `test` et du `train`. \n",
    "Celà peut affecter les performances des modèles. On va en général chercher à séparer le jeu de données en conservant \n",
    "dans le `train` et le `test` la même proportion de labels que dans le jeu de données initial : c'est la stratification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data_train, data_test, label_train, label_test = train_test_split(digits.data, digits.target, \n",
    "                                                                    test_size=0.3, random_state=84, stratify=digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(label_test)\n",
    "plt.xlabel('test labels')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(label_train)\n",
    "plt.xlabel('train labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage d'un classifieur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant entrainer un modèle sur le jeu d'entrainement (`data_train`, `label_train`) et le tester sur (`data_test`, `label_test`).\n",
    "\n",
    "Les modèles de sklearn sont implémentés par une classe héritée de `BaseEstimator`.\n",
    "On les utilise tous de la même manière, en 3 étapes:\n",
    "\n",
    "* Instancier le modèle `model(**kwargs)`\n",
    "* Apprendre le modèle sur le jeu d'entrainement avec la méthode `fit`: `model.fit(X=data, y=ground_truth)`.\n",
    "* Utiliser le modèle, avec les méthodes `predict`, `score` par exemple: `model.predict(X=data_test)`\n",
    "\n",
    "Rappel : on peut utiliser `dir(object)` pour lister les méthodes/attributs disponibles, et `help(object.methode)` pour afficher la doc de cette méthode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "## Instanciez, apprennez et testez un classifieur des 5-plus-proches-voisins.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est possible de créer des pipelines d'execution grace à `sklearn.pipeline.Pipeline`.\n",
    "De même qu'un autre modèle, une pipeline a des méthodes `fit`, `predict` etc...\n",
    "\n",
    "Implémentons la régression logistique régularisée, avec comme paramètre de régularisation $\\frac{1}{C} = \\frac{1}{2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "C = 2\n",
    "penalty='l2'\n",
    "lreg = LogisticRegression(penalty=penalty, C=C, max_iter=200)\n",
    "pip = Pipeline([('scaler', StandardScaler()), ('lreg', lreg)])\n",
    "\n",
    "# Apprenez et testez la regression logistique régularisée (précedeée d'une normalisation des données):\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons de plus près quelques exemples de succès et d'échec de l'algorithme 5-NNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(84)\n",
    "## instanciez `preds` avec les prédictions du 5-NNC sur le set de test.\n",
    "preds = \n",
    "\n",
    "success = np.array(preds) == np.array(label_test)   \n",
    "\n",
    "# Quelques cas de prédictions justes:\n",
    "data_s, pred_s, label_s =data_test[success,:], preds[success], label_test[success]\n",
    "sample = np.random.choice(len(pred_s), size=16) # Echantillon aléatoire de 16 succès\n",
    "plt.figure(figsize=(7, 7))\n",
    "for i in range(16):\n",
    "    ax = plt.subplot(4, 4, i+1)\n",
    "    pred, ground_truth = pred_s[sample][i], label_s[sample][i]\n",
    "    ax.imshow(data_s[sample,:][i,:].reshape((8,8)), cmap='Greys')\n",
    "    ax.set_title('Pred: {}, Label: {}'.format(pred, ground_truth), color='b')\n",
    "    ax.set_axis_off()\n",
    "\n",
    "# Quelques cas de prédictions fausses:\n",
    "data_f, pred_f, label_f =data_test[~success,:], preds[~success], label_test[~success]\n",
    "sample = np.random.choice(len(pred_f),size=16)\n",
    "plt.figure(figsize=(7, 7))\n",
    "for i in range(16):\n",
    "    ax = plt.subplot(4, 4, i+1)\n",
    "    pred, ground_truth = pred_f[sample][i], label_f[sample][i]\n",
    "    ax.imshow(data_f[sample,:][i,:].reshape((8,8)), cmap='Greys')\n",
    "    ax.set_title('Pred: {}, Label: {}'.format(pred, ground_truth), color='r')\n",
    "    ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation d'un algorithme de classification\n",
    "\n",
    "A l'oeil, sur un certain nombre d'échantillons ça semble assez bien fonctionner.\n",
    "On peut évaluer plus précisément les performances de cet algo. Pour ça, on va utiliser le module [`metrics`](https://scikit-learn.org/stable/modules/model_evaluation.html) de sklearn.\n",
    "On y trouve déjà implémenté une série de métriques utiles: [`accuracy`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score), [`f1_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score), [`auc_roc`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score).\n",
    "\n",
    "Vous noterez que tous les classifieurs de sklearn ont la méthode `score` qui calcule le score `accuracy` moyen sur un dataset donné. \n",
    "    \n",
    "De nombreuses autres métriques sont disponibles, pour évaluer la classification mais aussi d'autres tâches comme le clustering ou la régression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "acc = metrics.accuracy_score(y_true=label_test, y_pred=preds)\n",
    "f1_weighted = metrics.f1_score(label_test, preds, average='weighted')\n",
    "print('Accuracy : {}, f1 : {}'.format(acc, f1_weighted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le rapport de classification fournit une vue synthétique des performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = metrics.classification_report(y_true=label_test, y_pred=preds)\n",
    "print(report)\n",
    "\n",
    "## Il est possible de générer un dictionnaire des performances :\n",
    "## report_dict = metrics.classification_report(y_true=label_test, y_pred=preds, output_dict=True)\n",
    "## On accède alors aux performances concernant le label 0 par report_dict['0']."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrice de confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les prédictions d'un algorithme de classification peuvent être visualisés à l'aide de la matrice de confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "cm = metrics.confusion_matrix(y_true=label_test, y_pred=preds)\n",
    "ax = sns.heatmap(cm, cmap='coolwarm', annot=cm)\n",
    "ax.set_xlabel('True label')\n",
    "ax.set_ylabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichez la matrice de confusion de la regression logistique régularisée.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation, sélection de modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des prédictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si l'on utilise les deux premières composantes principales du jeu de données pour apprendre un classifieur k-NN, \n",
    "on peut représenter comment se 'comporte' l'algorithme en prédisant les labels de points interpolés entre les points du jeu d'entrainement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# On calcul les composantes principales du jeu de données, on le projette ensuite sur ses deux premiers axes.\n",
    "pca = PCA(n_components=2, whiten=True)\n",
    "X = pca.fit_transform(data_train)\n",
    "\n",
    "# On apprend un classifieur 1-NNC sur les deux premières composantes de chaque point de 'digits'\n",
    "knnc = KNeighborsClassifier(n_neighbors=1)\n",
    "knnc.fit(X=X, y=label_train)\n",
    "\n",
    "## On veut représenter la prédiction du knn : \n",
    "## pour celà on prédit sur un ensemble assez dense de coordonnées autour des points d'entrainement.\n",
    "## On colorera ces points en fonction de la prédiction du modèle\n",
    "\n",
    "h = .02 # Définit l'écart entre les points de la grille\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "cmap = plt.cm.get_cmap('magma', 10)\n",
    "Z = knnc.predict(np.c_[xx.ravel(), yy.ravel()]) #Prédiction d'un ensemble de points du plan des composantes principales.\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(figsize=(10,10))\n",
    "im=plt.pcolormesh(xx, yy, Z, cmap='magma',alpha=.8)\n",
    "plt.legend([mpatches.Patch(color=cmap(l)) for l in range(10)], [str(l) for l in range(10)])\n",
    "\n",
    "# On affiche un échantillon des points du jeu d'entrainement\n",
    "sample = np.random.choice(X.shape[0], size=250)\n",
    "plt.scatter(X[sample, 0], X[sample, 1], c=label_train[sample], cmap='magma', edgecolor='k', s=20)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut ainsi visualiser l'effet du paramètre `n_neighbors` sur la prédiction du modèle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "# On va afficher les prédictions du plan des composantes principales en fonction de n_neighbors.\n",
    "for o,k in enumerate([1, 5, 20, 50], 1):\n",
    "    knnc = KNeighborsClassifier(n_neighbors=k)\n",
    "    knnc.fit(X=X, y=label_train)\n",
    "    Z = knnc.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax = plt.subplot(2, 2, o)\n",
    "    ax.pcolormesh(xx, yy, Z, cmap='magma',alpha=.8, shading='auto')\n",
    "    ax.set_title('k = {}'.format(k))\n",
    "    ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:**\n",
    "\n",
    "> Quelle est la classe d'hypothèse du 1-plus-proche-voisin ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Réponse:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayez de représenter l'impact de $C$ sur l'apprentissage avec la régression logistique régularisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "# On va afficher les prédictions du plan des composantes principales en fonction de n_neighbors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Qu'observez-vous ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sélection de modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cherche à trouver le meilleur hyper paramètre `C` ou `n_neighbors`.\n",
    "Pour ce faire on peut effectuer une `grid search` : on va brutalement tester tous les hyperparamètres d'une liste (`grid` s'il y a plusieurs paramètres).\n",
    "On cherche à choisir le paramètre qui maximise les performances du modèle en généralisation. Un proxy pour cette performance est la performance estiméee sur le `test set`.\n",
    "Cependant, de la même façon qu'il est possible de surapprendre un jeu d'entrainement, il est possible de sur-apprendre un jeu de test par la sélection de l'hyperparamètre: l'hyperparamètre apporterait alors de bonnes performances pour ce jeu de test précis.\n",
    "\n",
    "Pour éviter celà au maximum, on va utiliser une `validation croisée`.\n",
    "\n",
    "![](crossval.001.jpeg)\n",
    "\n",
    "Dans cette illustration, la meilleure performance moyenne est rapportée par les modèles paramétrés par $\\text{n_neighbors}=2$. On sélectionne donc cet hyeraramètre la.\n",
    "\n",
    "En pratique, on utilise [`sklearn.model_selection.GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "\n",
    "Comme les autres estimateurs de sklearn, il faut instancier GridSearchCV et utiliser sa méthode `fit`.\n",
    "\n",
    "Les paramètres principaux du GridSearchCV sont :\n",
    "\n",
    "* `estimator` : le modèle de classification utilisé\n",
    "* `param_grid` : dictionnaire des hyperparamètres à tester. Les clés de ce dictionnaire sont de type `str` et correspondent exactement au nom du paramètre utilisé pour instancier `estimator`\n",
    "* `scoring`: définit selon quelle mesure sont sélectionnés les hyperparamètres.\n",
    "* `cv`: définit le nombre de sous-divisions du jeu de donnée\n",
    "\n",
    "Comme une selection (et donc une forme d'apprentissage) est faite à l'aide du jeu de validation, il nous faut conserver un jeu de set finale, sur lequel on pourra calculer la vraie performance de généralisation du modèle.\n",
    "Il convient donc d'appliquer la validation croisée sur `data_train`.\n",
    "\n",
    "Une fois \"fitté\" on a accès aux résultats grace à l'attribut `.cv_results_`.\n",
    "On peut aussi utiliser les méthodes `score` ou encore `predict`, qui reviennent à utiliser le meilleur modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "## Cherchez le meilleur paramètre n_neighbors pour l'algorithme\n",
    "## des k-plus proches voisins: GridSearchCV pour le k-NNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Représentez (d'une manière ou d'une autre) l'évolution des performances de validation \n",
    "## en fonction de n_neighbors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "stsc = StandardScaler()\n",
    "data_train = stsc.fit_transform(data_train)\n",
    "## Cherchez le meilleur paramètre C pour l'algorithme\n",
    "## de la régression logistique régularisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Représentez (d'une manière ou d'une autre) l'évolution des performances de validation \n",
    "## en fonction de C.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions:** \n",
    "> Expliquez l'effet de ces deux hyperparamètres sur l'apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Réponse**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On veut finalement choisir quel modèle utiliser entre le meilleur des k-NNC et des régressions logistiques régularisées. \n",
    "\n",
    "**Questions:**\n",
    "\n",
    "> Comment comparer et sélectionner entre ces deux modèles ? \\\n",
    "> Comment finir d'évaluer le résultat de cette sélection ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Réponses:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection et évaluation du modèle final."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
